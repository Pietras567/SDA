{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Projekt z przedmiotu Analiza Danych Przestrzennych**\n",
    "### Piotr Janiszek 247678\n",
    "### Kacper Białek 247629\n",
    "### Franciszek Pawlak 247756\n",
    "---\n",
    "\n",
    "#### Informacje o zbiorze danych i projekcie:\n",
    "Do projektu został wykorzystany zbiór danych dotyczący jakości powietrza w Polsce. Dane pochodzą z różnych punktów pomiarowych na terenie kraju, były zbierane na przestrzenii lat 2017-2023. Zbiór danych zawiera dokładne pomiary, zawierające zawartość określonych substancji w powietrzu, dzięki czemu można określić jego jakość.\n",
    "<br><br><br>\n",
    "Dostępny pod linkiem: [https://www.kaggle.com/datasets/wisekinder/poland-air-quality-monitoring-dataset-2017-2023/]()\n",
    "\n",
    "Podstawowym indeksem jakości w Polsce jest Polish air quality index (PAQI), a jego jakość obliczana jest według przedziałów z poniższej tabeli.\n",
    "![Kryteria](https://powietrze.gios.gov.pl/pjp/content/content_image/2855)\n",
    "<br>Zakresy poszczególnych progów charakteryzują się przedziałami lewostronnie otwartymi i prawostronnie domkniętymi, czyli dla przykładu wartość PM10 = 49,9 µg/m3 oraz PM10 = 50,0 µg/m3 przyjmuje indeks „Dobry”, natomiast PM10 = 50,1 µg/m3 jest dopiero indeksem „Umiarkowanym”. Przy przypisywaniu progów stosuje się takie same zasady, jak przy porównywaniu z wartościami norm. Np. gdy norma wynosi 50 µg/m3, to stężenie wynoszące 50 µg/m3 nie jest jeszcze jej przekroczeniem. Przy zaliczaniu wartości do klasy indeksu nie stosuje się zaokrągleń. Indeks odpowiada najgorszemu poziomowi dowolnego z 5 zanieczyszczeń zgodnie z powyższym schematem. Polski indeks jakości powietrza liczony jest na podstawie 1-godzinnych wyników z pomiarów stężeń w powietrzu: dwutlenku siarki (SO2), dwutlenku azotu (NO2), pyłu PM10, pyłu PM2,5, i ozonu (O3). Indeksy jakości powietrza dla poszczególnych zanieczyszczeń liczone są w oparciu o wartości 1-godzinnych stężeń tych zanieczyszczeń, przypisywanych do odpowiedniej kategorii z tabeli zakresów dla indeksów poszczególnych zanieczyszczeń. Następnie indeks ogólny przyjmuje wartość najgorszego indeksu indywidualnego spośród zanieczyszczeń mierzonych na tej stacji lub przyjmuje wartość zanieczyszczenia dominującego dla województwa (pył zawieszony lub ozon) lub indeks nie jest określany i wyświetlany jest w kolorze szarym. „Brak indeksu” wskazuje na to, iż na danej stacji nie prowadzi się automatycznych pomiarów zanieczyszczenia, które w danym czasie decyduje o jakości powietrza na obszarze województwa. W okresie jesienno-zimowym dotyczy to przeważnie pyłu zawieszonego PM2,5/PM10, a w okresie wiosenno-letnim – ozonu.\n",
    "<br><br>\n",
    "Zaś dla poszczególnych kategorii Polskiego Indeksu Jakości Powietrza wyróżnić możemy następujące informacje zdrowotne:<br>\n",
    "**Bardzo dobry** - Jakość powietrza jest bardzo dobra, zanieczyszczenie powietrza nie stanowi zagrożenia dla zdrowia, warunki bardzo sprzyjające do wszelkich aktywności na wolnym powietrzu, bez ograniczeń.<br>\n",
    "**Dobry** - Jakość powietrza jest zadowalająca, zanieczyszczenie powietrza powoduje brak lub niskie ryzyko zagrożenia dla zdrowia. Można przebywać na wolnym powietrzu i wykonywać dowolną aktywność, bez ograniczeń.<br>\n",
    "**Umiarkowany** - Jakość powietrza jest akceptowalna. Zanieczyszczenie powietrza może stanowić zagrożenie dla zdrowia w szczególnych przypadkach (dla osób chorych, osób starszych, kobiet w ciąży oraz małych dzieci). Warunki umiarkowane do aktywności na wolnym powietrzu.<br>\n",
    "**Dostateczny** - Jakość powietrza jest dostateczna, zanieczyszczenie powietrza stanowi zagrożenie dla zdrowia (szczególnie dla osób chorych, starszych, kobiet w ciąży oraz małych dzieci) oraz może mieć negatywne skutki zdrowotne. Należy rozważyć ograniczenie (skrócenie lub rozłożenie w czasie) aktywności na wolnym powietrzu, szczególnie jeśli ta aktywność wymaga długotrwałego lub wzmożonego wysiłku fizycznego.<br>\n",
    "**Zły** - Jakość powietrza jest zła, osoby chore, starsze, kobiety w ciąży oraz małe dzieci powinny unikać przebywania na wolnym powietrzu. Pozostała populacja powinna ograniczyć do minimum wszelką aktywność fizyczną na wolnym powietrzu - szczególnie wymagającą długotrwałego lub wzmożonego wysiłku fizycznego.<br>\n",
    "**Bardzo zły** - Jakość powietrza jest bardzo zła i ma negatywny wpływ na zdrowie. Osoby chore, starsze, kobiety w ciąży oraz małe dzieci powinny bezwzględnie unikać przebywania na wolnym powietrzu. Pozostała populacja powinna ograniczyć przebywanie na wolnym powietrzu do niezbędnego minimum. Wszelkie aktywności fizyczne na zewnątrz są odradzane. Długotrwała ekspozycja na działanie substancji znajdujących się w powietrzu zwiększa ryzyko wystąpienia zmian m.in. w układzie oddechowym, naczyniowo-sercowym oraz odpornościowym.<br>\n",
    "**Brak indeksu** - „Brak Indeksu” odpowiada sytuacji, gdy na danej stacji pomiarowej nie są aktualnie prowadzone pomiary pyłu zawieszonego lub ozonu, a jeden z nich jest w danej chwili decydującym zanieczyszczeniem powietrza w województwie. Indeks Jakości Powietrza nie jest wtedy wyznaczany, a kolor punktów na mapie bieżących danych pomiarowych zmienia się na szary. Stacja pomimo braku określonego Indeksu jest nadal widoczna i jest możliwość sprawdzenia wszystkich pozostałych wyników pomiarów.<br><br>\n",
    "\n",
    "\n",
    "[https://powietrze.gios.gov.pl/pjp/content/health_informations]()\n",
    "\n",
    "\n",
    "---\n",
    "#### Cele projektu:\n",
    "1. Zidentyfikowanie wzorców jakości powietrza w różnych regionach Polski.\n",
    "2. Zrozumienie zależności między jakością powietrza a różnymi czynnikami (np. przemysł, ruch drogowy, warunki pogodowe).\n",
    "3. Stworzenie interaktywnych map, które umożliwią wizualizację danych i ułatwią ich analizę.\n",
    "4. Wyciągnięcie wniosków, które mogą pomóc w opracowaniu strategii poprawy jakości powietrza.\n",
    "\n",
    "---\n",
    "#### Zakres projektu:\n",
    "1. Zbieranie danych o jakości powietrza z różnych źródeł, to jest punktów pomiarowych rozlokowanych w oddalonych od siebie lokacjach Polski.\n",
    "2. Analiza statystyczna zebranych danych w celu zidentyfikowania trendów i anomalii.\n",
    "3. Wizualizacja danych, poprzez stworzenie interaktywnych map, co pozwoli na dogodną obserwację danych historycznych dla jednego momentu w czasie lub na pewnym przedziale.\n",
    "4. Opracowanie wniosków na podstawie analizowanych danych.\n",
    "\n",
    "---\n",
    "#### Problem oraz hipoteza:\n",
    "Zanieczyszczenie powietrza jest poważnym problemem zdrowotnym i środowiskowym w różnych regionach Polski, m. in. na Śląsku oraz w Małopolsce stanowi to wyjątkowo duży kłopot. Wpływa na zdrowie mieszkańców, przyczynia się do zmian klimatycznych i negatywnie oddziałuje na ekosystemy. Czynniki takie jak intensywność ruchu drogowego, działalność przemysłowa oraz warunki pogodowe znacząco wpływają na jakość powietrza w różnych regionach Polski.\n",
    "\n",
    "---\n",
    "#### Potrzeba projektu:\n",
    "Wysokiej jakości dane oraz analizy pomogą w lepszym zrozumieniu problemu zanieczyszczenia powietrza oraz w opracowaniu skutecznych strategii na rzecz jego redukcji. Interaktywne mapy umożliwią społeczeństwu i decydentom łatwiejszy dostęp do informacji i ułatwią podejmowanie świadomych decyzji."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "c022208e4febd50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "from cmath import isnan\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import folium\n",
    "from IPython.display import display\n",
    "from folium.plugins import HeatMap, Search, TimestampedGeoJson\n",
    "from shapely.geometry.point import Point\n",
    "import base64\n"
   ],
   "id": "548cca41a2c8b170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data loading",
   "id": "a43dceaa068a99d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gdf1 = gpd.read_file('data/powiaty-max.geojson')\n",
    "gdf2 = gpd.read_file('data/wojewodztwa-max.geojson')\n",
    "\n",
    "print(gdf1.crs)\n",
    "print(gdf2.crs)\n",
    "\n",
    "gdf1 = gdf1.to_crs(epsg=2180)\n",
    "gdf2 = gdf2.to_crs(epsg=2180)\n",
    "\n",
    "print(gdf1.crs)\n",
    "print(gdf2.crs)\n",
    "\n",
    "display(gdf1)\n",
    "display(gdf2)\n",
    "\n",
    "gdf3 = pd.read_csv('data/stations_metadata.csv', sep=';')\n",
    "display(gdf3)"
   ],
   "id": "dea30f2c2dd2251e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Layer styles",
   "id": "8b39e8ca628b84f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def style_function_1(feature):\n",
    "    return {\n",
    "        'fillColor': '#29CED4',\n",
    "        'color': '#2D7A7D',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0.5,\n",
    "        'z-index': 100\n",
    "    }\n",
    "\n",
    "def style_function_2(feature):\n",
    "    return {\n",
    "        'fillColor': '#7536C7',\n",
    "        'color': '#3E1573',\n",
    "        'weight': 3,\n",
    "        'fillOpacity': 0.5,\n",
    "        'z-index': 200\n",
    "    }\n"
   ],
   "id": "ab6a15b96b3a30e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Interactive map",
   "id": "eb0e83742dac30e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "m = folium.Map(location=[51.77513554189464, 19.455341364192083], zoom_start=6, tiles='CartoDB positron')\n",
    "\n",
    "layer1 = folium.GeoJson(gdf1, name=\"Powiaty\", show=False, style_function=style_function_1, overlay=True, control=True).add_to(m)\n",
    "\n",
    "layer2 = folium.GeoJson(gdf2, name=\"Województwa\", show=False, style_function=style_function_2, overlay=True, control=True).add_to(m)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -1 Brak indeksu\n",
    "#  0 Bardzo dobry\n",
    "#  1 Dobry\n",
    "#  2 Umiarkowany\n",
    "#  3 Dostateczny\n",
    "#  4 Zły\n",
    "#  5 Bardzo zły\n",
    "\n",
    "def NO2(value):\n",
    "    ranges = {\n",
    "        (0, 40): 0,\n",
    "        (40.1, 100): 1,\n",
    "        (100.1, 150): 2,\n",
    "        (150.1, 230): 3,\n",
    "        (230.1, 400): 4,\n",
    "        (400.1, float('inf')): 5,\n",
    "    }\n",
    "    for (low, high), label in ranges.items():\n",
    "        if low < value <= high:\n",
    "            return label\n",
    "    return -1\n",
    "\n",
    "def SO2(value):\n",
    "    ranges = {\n",
    "        (0, 50): 0,\n",
    "        (50.1, 100): 1,\n",
    "        (100.1, 200): 2,\n",
    "        (200.1, 350): 3,\n",
    "        (350.1, 800): 4,\n",
    "        (800.1, float('inf')): 5,\n",
    "    }\n",
    "    for (low, high), label in ranges.items():\n",
    "        if low < value <= high:\n",
    "            return label\n",
    "    return -1\n",
    "\n",
    "def PM25(value):\n",
    "    ranges = {\n",
    "        (0, 13): 0,\n",
    "        (13.1, 35): 1,\n",
    "        (35.1, 55): 2,\n",
    "        (55.1, 75): 3,\n",
    "        (75.1, 110): 4,\n",
    "        (110.1, float('inf')): 5,\n",
    "    }\n",
    "    for (low, high), label in ranges.items():\n",
    "        if low < value <= high:\n",
    "            return label\n",
    "    return -1\n",
    "\n",
    "def PM10(value):\n",
    "    ranges = {\n",
    "        (0, 20): 0,\n",
    "        (20.1, 50): 1,\n",
    "        (50.1, 80): 2,\n",
    "        (80.1, 110): 3,\n",
    "        (110.1, 150): 4,\n",
    "        (150.1, float('inf')): 5,\n",
    "    }\n",
    "    for (low, high), label in ranges.items():\n",
    "        if low < value <= high:\n",
    "            return label\n",
    "    return -1\n",
    "\n",
    "def O3(value):\n",
    "    ranges = {\n",
    "        (0, 70): 0,\n",
    "        (70.1, 120): 1,\n",
    "        (120.1, 150): 2,\n",
    "        (150.1, 180): 3,\n",
    "        (180.1, 240): 4,\n",
    "        (240.1, float('inf')): 5,\n",
    "    }\n",
    "    for (low, high), label in ranges.items():\n",
    "        if low < value <= high:\n",
    "            return label\n",
    "    return -1\n",
    "\n",
    "\n"
   ],
   "id": "f488b6dab458b29b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_air_quality(row):\n",
    "    #point_data = averages.isin([row])\n",
    "    #print(row)\n",
    "\n",
    "    qualities = []\n",
    "    \n",
    "    #print((row['NO2']))\n",
    "\n",
    "    if 'NO2' in row and not pd.isna((row['NO2'].item())):\n",
    "        qualities.append(NO2((row['NO2']).item()))\n",
    "    if 'SO2' in row and not pd.isna((row['SO2'].item())):\n",
    "        qualities.append(SO2((row['SO2']).item()))\n",
    "    if 'PM25' in row and not pd.isna((row['PM25'].item())):\n",
    "        qualities.append(PM25((row['PM25']).item()))\n",
    "    if 'PM10' in row and not pd.isna((row['PM10'].item())):\n",
    "        qualities.append(PM10((row['PM10']).item()))\n",
    "    if 'O3' in row and not pd.isna((row['O3'].item())):\n",
    "        qualities.append(O3((row['O3']).item()))\n",
    "    if len(qualities) == 0:\n",
    "        qualities.append(-1)\n",
    "    #print(qualities)\n",
    "    #print(max(qualities))\n",
    "    return max(qualities)\n",
    "\n",
    "def get_air_quality_style(quality): \n",
    "    if quality == 0:\n",
    "        return ('fa-solid fa-face-grin-beam', 'green')\n",
    "    if quality == 1:\n",
    "        return ('fa-solid fa-face-smile-beam', 'lightgreen')\n",
    "    if quality == 2:\n",
    "        return ('fa-solid fa-face-meh', 'yellow')\n",
    "    if quality == 3:\n",
    "        return ('fa-solid fa-face-frown', 'orange')\n",
    "    if quality == 4:\n",
    "        return ('fa-solid fa-face-sad-tear', 'red')\n",
    "    if quality == 5:\n",
    "        return ('fa-solid fa-face-angry', 'brown')\n",
    "    else:\n",
    "        return ('fa-solid fa-question', 'purple')\n"
   ],
   "id": "b7e9aa04b582c641",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Funkcja do wczytania danych, transpozycji i obliczenia średnich\n",
    "def calculate_averages(file_path, element_name):\n",
    "    df = pd.read_csv(file_path, sep=',')\n",
    "    df = df.iloc[:, 1:]\n",
    "    new_columns = [col.split('-')[0] for col in df.columns]\n",
    "    df.columns = new_columns\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df.mean(axis=0).rename(element_name).round(1)\n",
    "\n",
    "# Lista plików do przetworzenia\n",
    "files_2017 = {\n",
    "    'NO2': 'data/2017_NO2_1g.csv',\n",
    "    'SO2': 'data/2017_SO2_1g.csv',\n",
    "    'PM10': 'data/2017_PM10_1g.csv',\n",
    "    'PM25': 'data/2017_PM25_1g.csv',\n",
    "    'O3': 'data/2017_O3_1g.csv'\n",
    "}\n",
    "\n",
    "files_2018 = {\n",
    "    'NO2': 'data/2018_NO2_1g.csv',\n",
    "    'SO2': 'data/2018_SO2_1g.csv',\n",
    "    'PM10': 'data/2018_PM10_1g.csv',\n",
    "    'PM25': 'data/2018_PM25_1g.csv',\n",
    "    'O3': 'data/2018_O3_1g.csv'\n",
    "}\n",
    "\n",
    "files_2019 = {\n",
    "    'NO2': 'data/2019_NO2_1g.csv',\n",
    "    'SO2': 'data/2019_SO2_1g.csv',\n",
    "    'PM10': 'data/2019_PM10_1g.csv',\n",
    "    'PM25': 'data/2019_PM25_1g.csv',\n",
    "    'O3': 'data/2019_O3_1g.csv'\n",
    "}\n",
    "\n",
    "files_2020 = {\n",
    "    'NO2': 'data/2020_NO2_1g.csv',\n",
    "    'SO2': 'data/2020_SO2_1g.csv',\n",
    "    'PM10': 'data/2020_PM10_1g.csv',\n",
    "    'PM25': 'data/2020_PM25_1g.csv',\n",
    "    'O3': 'data/2020_O3_1g.csv'\n",
    "}\n",
    "\n",
    "files_2021 = {\n",
    "    'NO2': 'data/2021_NO2_1g.csv',\n",
    "    'SO2': 'data/2021_SO2_1g.csv',\n",
    "    'PM10': 'data/2021_PM10_1g.csv',\n",
    "    'PM25': 'data/2021_PM25_1g.csv',\n",
    "    'O3': 'data/2021_O3_1g.csv'\n",
    "}\n",
    "\n",
    "files_2022 = {\n",
    "    'NO2': 'data/2022_NO2_1g.csv',\n",
    "    'SO2': 'data/2022_SO2_1g.csv',\n",
    "    'PM10': 'data/2022_PM10_1g.csv',\n",
    "    'PM25': 'data/2022_PM25_1g.csv',\n",
    "    'O3': 'data/2022_O3_1g.csv'\n",
    "}\n",
    "\n",
    "files_2023 = {\n",
    "    'NO2': 'data/2023_NO2_1g.csv',\n",
    "    'SO2': 'data/2023_SO2_1g.csv',\n",
    "    'PM10': 'data/2023_PM10_1g.csv',\n",
    "    'PM25': 'data/2023_PM25_1g.csv',\n",
    "    'O3': 'data/2023_O3_1g.csv'\n",
    "}\n",
    "\n",
    "files_joint = {\n",
    "    'NO2': 'data/NO2_1g_joint_2017-2023.csv',\n",
    "    'SO2': 'data/SO2_1g_joint_2017-2023.csv',\n",
    "    'PM10': 'data/PM10_1g_joint_2017-2023.csv',\n",
    "    'PM25': 'data/PM25_1g_joint_2017-2023.csv',\n",
    "    'O3': 'data/O3_1g_joint_2017-2023.csv'\n",
    "}\n",
    "\n",
    "# Przechowuje średnie dla każdego punktu w latach 2017-2023\n",
    "averages_2017 = pd.DataFrame()\n",
    "averages_2018 = pd.DataFrame()\n",
    "averages_2019 = pd.DataFrame()\n",
    "averages_2020 = pd.DataFrame()\n",
    "averages_2021 = pd.DataFrame()\n",
    "averages_2022 = pd.DataFrame()\n",
    "averages_2023 = pd.DataFrame()\n",
    "averages_joint = pd.DataFrame()\n",
    "\n",
    "averages = []\n",
    "\n",
    "# Oblicz średnie dla każdego pliku\n",
    "#2017\n",
    "for element, file in files_2017.items():\n",
    "    element_averages = calculate_averages(file, element)  # Średnie dla danego pierwiastka\n",
    "    averages_2017[element] = element_averages  # Dodaj jako kolumnę\n",
    "\n",
    "averages_2017.reset_index(inplace=True)  # Zresetuj indeks, aby \"punkty\" były kolumną\n",
    "averages_2017.rename(columns={'index': 'Point'}, inplace=True)  # Nazwij kolumnę z punktami\n",
    "averages.append([averages_2017, '2017'])\n",
    "#2018\n",
    "for element, file in files_2018.items():\n",
    "    element_averages = calculate_averages(file, element)  # Średnie dla danego pierwiastka\n",
    "    averages_2018[element] = element_averages  # Dodaj jako kolumnę\n",
    "\n",
    "averages_2018.reset_index(inplace=True)  # Zresetuj indeks, aby \"punkty\" były kolumną\n",
    "averages_2018.rename(columns={'index': 'Point'}, inplace=True)  # Nazwij kolumnę z punktami\n",
    "averages.append([averages_2018, '2018'])\n",
    "#2019\n",
    "for element, file in files_2019.items():\n",
    "    element_averages = calculate_averages(file, element)  # Średnie dla danego pierwiastka\n",
    "    averages_2019[element] = element_averages  # Dodaj jako kolumnę\n",
    "\n",
    "averages_2019.reset_index(inplace=True)  # Zresetuj indeks, aby \"punkty\" były kolumną\n",
    "averages_2019.rename(columns={'index': 'Point'}, inplace=True)  # Nazwij kolumnę z punktami\n",
    "averages.append([averages_2019, '2019'])\n",
    "#2020\n",
    "for element, file in files_2020.items():\n",
    "    element_averages = calculate_averages(file, element)  # Średnie dla danego pierwiastka\n",
    "    averages_2020[element] = element_averages  # Dodaj jako kolumnę\n",
    "\n",
    "averages_2020.reset_index(inplace=True)  # Zresetuj indeks, aby \"punkty\" były kolumną\n",
    "averages_2020.rename(columns={'index': 'Point'}, inplace=True)  # Nazwij kolumnę z punktami\n",
    "averages.append([averages_2020, '2020'])\n",
    "#2021\n",
    "for element, file in files_2021.items():\n",
    "    element_averages = calculate_averages(file, element)  # Średnie dla danego pierwiastka\n",
    "    averages_2021[element] = element_averages  # Dodaj jako kolumnę\n",
    "\n",
    "averages_2021.reset_index(inplace=True)  # Zresetuj indeks, aby \"punkty\" były kolumną\n",
    "averages_2021.rename(columns={'index': 'Point'}, inplace=True)  # Nazwij kolumnę z punktami\n",
    "averages.append([averages_2021, '2021'])\n",
    "#2022\n",
    "for element, file in files_2022.items():\n",
    "    element_averages = calculate_averages(file, element)  # Średnie dla danego pierwiastka\n",
    "    averages_2022[element] = element_averages  # Dodaj jako kolumnę\n",
    "\n",
    "averages_2022.reset_index(inplace=True)  # Zresetuj indeks, aby \"punkty\" były kolumną\n",
    "averages_2022.rename(columns={'index': 'Point'}, inplace=True)  # Nazwij kolumnę z punktami\n",
    "averages.append([averages_2022, '2022'])\n",
    "#2023\n",
    "for element, file in files_2023.items():\n",
    "    element_averages = calculate_averages(file, element)  # Średnie dla danego pierwiastka\n",
    "    averages_2023[element] = element_averages  # Dodaj jako kolumnę\n",
    "\n",
    "averages_2023.reset_index(inplace=True)  # Zresetuj indeks, aby \"punkty\" były kolumną\n",
    "averages_2023.rename(columns={'index': 'Point'}, inplace=True)  # Nazwij kolumnę z punktami\n",
    "averages.append([averages_2023, '2023'])\n",
    "#Wszystkie lata\n",
    "for element, file in files_joint.items():\n",
    "    element_averages = calculate_averages(file, element)  # Średnie dla danego pierwiastka\n",
    "    averages_joint[element] = element_averages  # Dodaj jako kolumnę\n",
    "\n",
    "averages_joint.reset_index(inplace=True)  # Zresetuj indeks, aby \"punkty\" były kolumną\n",
    "averages_joint.rename(columns={'index': 'Point'}, inplace=True)  # Nazwij kolumnę z punktami\n",
    "averages.append([averages_joint, 'joint'])\n",
    "\n",
    "\n"
   ],
   "id": "8de7f83033abdf72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "quality_map = {\n",
    "    -1: 'Brak indeksu',\n",
    "    0: 'Bardzo dobre',\n",
    "    1: 'Dobre',\n",
    "    2: 'Umiarkowane',\n",
    "    3: 'Średnie',\n",
    "    4: 'Złe',\n",
    "    5: 'Bardzo złe',\n",
    "}\n",
    "\n",
    "for averages_data, year in averages:\n",
    "    #print(averages_data.head())\n",
    "    #print(year)\n",
    "    \n",
    "    feature_group = folium.FeatureGroup(name=f'Dane {year}', show=(year == '2023'))\n",
    "\n",
    "    for _, row in gdf3.iterrows():\n",
    "        filtered_df = averages_data[averages_data['Point'].isin([row['StationID']])]\n",
    "\n",
    "        if not filtered_df.empty:\n",
    "            quality = calculate_air_quality(filtered_df)\n",
    "            icon_name, icon_color = get_air_quality_style(quality)\n",
    "            \n",
    "            # Przygotowanie opisu dla popup\n",
    "            popup_html = f\"\"\"\n",
    "            <div>\n",
    "                <h4>{row['StationName']}</h4>\n",
    "                <p><strong>ID punktu pomiarowego:</strong> {row['StationID']}</p>\n",
    "                <p><strong>Jakość powietrza:</strong> {quality_map.get(quality)}</p>\n",
    "                <p><strong>Dane szczegółowe [µg/m<sup>3</sup>]:</strong></p>\n",
    "                {filtered_df.iloc[:, 1:].to_html(index=False, escape=False)}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "            html_icon = f\"\"\"\n",
    "            <div style=\"\n",
    "                background-color: #1f033f; /* Kolor kółka */\n",
    "                border-radius: 50%; /* Zaokrąglenie, aby utworzyć kółko */\n",
    "                width: 22px; /* Szerokość kółka */\n",
    "                height: 22px; /* Wysokość kółka */\n",
    "                display: flex; /* Ustawienia do centrowania ikony */\n",
    "                align-items: center; /* Wyrównanie pionowe */\n",
    "                justify-content: center; /* Wyrównanie poziome */\n",
    "            \">\n",
    "                <i class=\"{icon_name}\" style=\"color: {icon_color}; font-size: 22px;\"></i>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            marker = folium.Marker(\n",
    "                location=[row['lat'], row['long']],\n",
    "                popup=folium.Popup(popup_html, max_width=300),\n",
    "                icon=folium.DivIcon(html=html_icon),\n",
    "                tooltip=row['StationName'],\n",
    "            ).add_to(feature_group)\n",
    "\n",
    "    feature_group.add_to(m)\n",
    "\n",
    "# Warstwa do wyszukiwania (niewidoczna dla użytkownika)\n",
    "search_layer = folium.FeatureGroup(name=\"Wyszukiwanie\", show=False)\n",
    "\n",
    "for _, row in gdf3.iterrows():\n",
    "    #print(row)\n",
    "    # Dodanie znacznika do warstwy wyszukiwania\n",
    "    search_marker = folium.Marker(\n",
    "        location=[row['lat'], row['long']],\n",
    "        #popup=folium.Popup(popup_html, max_width=300),\n",
    "        tooltip=row['StationName'],\n",
    "    )\n",
    "    #print(row['StationName'])\n",
    "    search_marker.add_to(search_layer)\n",
    "\n",
    "# Dodanie wyszukiwarki\n",
    "search = Search(\n",
    "    layer=search_layer,\n",
    "    geom_type=\"Point\",\n",
    "    search_label=\"tooltip\",\n",
    "    placeholder=\"Szukaj punktu...\",\n",
    "    collapsed=False,\n",
    ").add_to(m)\n",
    "\n",
    "search_layer.add_to(m)\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "m.save('mapa.html')\n",
    "\n",
    "m"
   ],
   "id": "cda5197677919b53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Gif przedstawiający zmianę w czasie\n",
    "\n",
    "\n",
    "def svg_to_base64(file_path):\n",
    "    \"\"\"Konwertuje plik SVG na ciąg Base64.\"\"\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:image/svg+xml;base64,{encoded}\"\n",
    "\n",
    "def get_air_quality_style_url(quality):\n",
    "    if quality == 0:\n",
    "        return svg_to_base64(\"face-grin-beam-solid.svg\")\n",
    "    if quality == 1:\n",
    "        return svg_to_base64(\"face-smile-beam-solid.svg\")\n",
    "    if quality == 2:\n",
    "        return svg_to_base64(\"face-meh-solid.svg\")\n",
    "    if quality == 3:\n",
    "        return svg_to_base64(\"face-frown-solid.svg\")\n",
    "    if quality == 4:\n",
    "        return svg_to_base64(\"face-sad-tear-solid.svg\")\n",
    "    if quality == 5:\n",
    "        return svg_to_base64(\"face-angry-solid.svg\")\n",
    "    else:\n",
    "        return svg_to_base64(\"circle-question-solid.svg\")\n",
    "\n",
    "def convert_to_geojson(qualities, current_date):\n",
    "    features = []\n",
    "    for quality in qualities:\n",
    "        station_id, coords, air_quality = quality\n",
    "        icon = get_air_quality_style_url(air_quality)\n",
    "        popup_text = f\"Stacja: {station_id}<br>Jakość powietrza: {quality_map.get(air_quality)}\"\n",
    "        \n",
    "        features.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": coords  # [long, lat]\n",
    "            },\n",
    "            'properties': {\n",
    "                'time': current_date.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "                'icon': 'marker',\n",
    "                'iconstyle': {\n",
    "                    \"iconUrl\": icon,\n",
    "                    'iconSize': [20, 20],\n",
    "                },\n",
    "                'popup': popup_text,\n",
    "                'station': station_id,\n",
    "                'air_quality': air_quality\n",
    "            }\n",
    "        })\n",
    "    return {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "\n",
    "m = folium.Map(location=[51.77513554189464, 19.455341364192083], zoom_start=6, tiles='CartoDB positron')\n",
    "\n",
    "# Dodajemy odpowiedni link do CDN Font Awesome\n",
    "html_header = \"\"\"\n",
    "<head>\n",
    "    <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css\" rel=\"stylesheet\">\n",
    "</head>\n",
    "\"\"\"\n",
    "\n",
    "# Tworzenie HTML z mapą\n",
    "m.get_root().header.add_child(folium.Element(html_header))\n",
    "\n",
    "# Przetwarzanie danych\n",
    "dataframes = []\n",
    "\n",
    "for element, file_path in files_joint.items():\n",
    "    df = pd.read_csv(file_path, sep=',')\n",
    "    dataframes.append([element, df])\n",
    "\n",
    "\n",
    "# Ustawienie daty początkowej i końcowej\n",
    "start_date = datetime(2017, 1, 1, 12, 0)\n",
    "end_date = datetime(2024, 1, 1, 1, 0)\n",
    "\n",
    "# Ustawienie odstępu godzinowego\n",
    "interval = timedelta(hours=120)\n",
    "\n",
    "# Lista do zbierania danych dla całego okresu\n",
    "all_geojson_data = []\n",
    "\n",
    "# Przemieszczanie się od start_date do end_date w odstępach godzinowych\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    #print(current_date)\n",
    "    \n",
    "    data = defaultdict(list)\n",
    "    qualities = []\n",
    "    for dataframe in dataframes:\n",
    "        filtered_df = dataframe[1][dataframe[1]['Time'] == current_date.strftime('%Y-%m-%dT%H:%M:%S')]\n",
    "        new_columns = [col.split('-')[0] for col in filtered_df.columns]\n",
    "        filtered_df.columns = new_columns\n",
    "\n",
    "        for _, point in filtered_df.iloc[:, 1:].T.iterrows():\n",
    "            data[point.name].append([dataframe[0], point.iloc[0]])\n",
    "\n",
    "        max_len = max(len(lst) for lst in data.values())\n",
    "        for key in data:\n",
    "            while len(data[key]) < max_len:\n",
    "                data[key].append(None)\n",
    "    indexes = pd.DataFrame(dict(data))\n",
    "    \n",
    "    for _, i in indexes.T.iterrows():\n",
    "        # Konwersja danych do słownika\n",
    "        pollution_data = {item[0]: float(item[1]) if item[1] != 'nan' else None for item in i.dropna()}\n",
    "        \n",
    "        # Tworzenie serii Pandas ze słownika\n",
    "        pollution_series = pd.Series(pollution_data)\n",
    "    \n",
    "        # Wywołanie funkcji calculate_air_quality\n",
    "        try:\n",
    "            air_quality = calculate_air_quality(pollution_series)\n",
    "            \n",
    "            station_data = gdf3[gdf3['StationID'] == i.name]\n",
    "            if not station_data.empty:  \n",
    "        \n",
    "                lat = station_data['lat'].iloc[0]\n",
    "                long = station_data['long'].iloc[0]\n",
    "            \n",
    "                qualities.append([i.name, [long, lat], air_quality])\n",
    "        except Exception as e:\n",
    "            print(f\"Błąd podczas obliczania jakości powietrza dla {i.name}: {e}\")\n",
    "    \n",
    "    # Konwersja do GeoJSON\n",
    "    geojson_data = convert_to_geojson(qualities, current_date)\n",
    "    all_geojson_data.append(geojson_data)\n",
    "    \n",
    "    current_date += interval\n",
    "\n",
    "# Dodanie warstwy czasowej\n",
    "TimestampedGeoJson(\n",
    "    data={\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": [feature for geojson in all_geojson_data for feature in geojson['features']]\n",
    "    },\n",
    "    transition_time=2000,\n",
    "    period=\"P5D\",\n",
    "    duration = 'P5D',\n",
    "    add_last_point=True,\n",
    "    auto_play=False,\n",
    "    loop=False\n",
    ").add_to(m)\n",
    "\n",
    "# Zapis mapy do pliku HTML\n",
    "m.save(f'air_quality_timeline_map.html')\n",
    "    \n"
   ],
   "id": "6968025b917a43a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Heatmap",
   "id": "dfff45d722955d5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#heatmap\n",
    "m = folium.Map(location=[51.77513554189464, 19.455341364192083], zoom_start=6, tiles='CartoDB positron')\n",
    "\n",
    "layer1 = folium.GeoJson(gdf1, name=\"Powiaty\", show=False, style_function=style_function_1, overlay=True, control=True).add_to(m)\n",
    "\n",
    "layer2 = folium.GeoJson(gdf2, name=\"Województwa\", show=False, style_function=style_function_2, overlay=True, control=True).add_to(m)\n",
    "\n",
    "norm_df = averages_2023.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "for column in norm_df:\n",
    "    norm_df[column] =(norm_df[column]-norm_df[column].min())/(norm_df[column].max()-norm_df[column].min())\n",
    "normalized_averages = pd.concat([averages_2023.iloc[:, :1], norm_df], axis=1)\n",
    "\n",
    "heat_data = []\n",
    "\n",
    "for _, row in gdf3.iterrows():\n",
    "    filtered_df = normalized_averages[normalized_averages['Point'].isin([row['StationID']])]\n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        #print(f\"Punkt {row['StationID']} istnieje w DataFrame:\")\n",
    "        #print(filtered_df)\n",
    "        pass\n",
    "    else:\n",
    "        #print(f\"Punkt {row['StationID']} nie istnieje w DataFrame.\")\n",
    "        continue\n",
    "    \n",
    "    sum_normalized_value = 0\n",
    "    for column in filtered_df.iloc[:, 1:]:\n",
    "        if pd.isna(filtered_df[column].values):\n",
    "            continue\n",
    "        sum_normalized_value += filtered_df[column].values\n",
    "    \n",
    "    heat_data.append([row['lat'], row['long'], sum_normalized_value[0]])\n",
    "    \n",
    "HeatMap(heat_data).add_to(m)\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "m.save('heat_mapa.html')\n",
    "\n",
    "m\n"
   ],
   "id": "3250e53c7fa348a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analiza statystyczna zanieczyszczenia powietrza według województwa\n",
    "# Przetwarzanie danych\n",
    "dataframes_2023 = []\n",
    "\n",
    "for element, file_path in files_2023.items():\n",
    "    df = pd.read_csv(file_path, sep=',')\n",
    "    dataframes_2023.append([element, df])\n",
    "\n",
    "# Tworzenie GeoDataFrame z punktami\n",
    "gdf3 = gpd.GeoDataFrame(\n",
    "    gdf3,\n",
    "    geometry=gpd.points_from_xy(gdf3['long'], gdf3['lat']),\n",
    "    crs='EPSG:4326'  # System odniesienia (WGS84)\n",
    ")\n",
    "gdf3 = gdf3.to_crs(\"EPSG:2180\")\n",
    "\n",
    "gdf2 = gdf2.rename(columns={'nazwa': 'wojewodztwo'})\n",
    "\n",
    "#punkty_gdf = gpd.sjoin(punkty_gdf, gdf2, how=\"left\")\n",
    "gdf3 = gpd.sjoin(gdf3, gdf2, how=\"left\")\n",
    "\n",
    "\n",
    "#display(punkty_gdf)\n",
    "\n",
    "# Ustawienie daty początkowej i końcowej\n",
    "start_date = datetime(2023, 1, 1, 1, 0)\n",
    "end_date = datetime(2024, 1, 1, 1, 0)\n",
    "\n",
    "# Ustawienie odstępu godzinowego\n",
    "interval = timedelta(hours=24)\n",
    "\n",
    "# Lista do zbierania danych dla całego okresu\n",
    "all_data = []\n",
    "\n",
    "\n",
    "# Przemieszczanie się od start_date do end_date w odstępach godzinowych\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    data = defaultdict(list)\n",
    "    qualities = []\n",
    "    \n",
    "    for dataframe in dataframes_2023:\n",
    "        #element = dataframe[0]\n",
    "        \n",
    "        filtered_df = dataframe[1][dataframe[1]['Time'] == current_date.strftime('%Y-%m-%dT%H:%M:%S')]\n",
    "        new_columns = [col.split('-')[0] for col in filtered_df.columns]\n",
    "        filtered_df.columns = new_columns\n",
    "        \n",
    "        #new_columns = [col.split('-')[0] for col in dataframe[1].columns]\n",
    "        #dataframe[1].columns = new_columns\n",
    "        \n",
    "        #display(dataframe[1])\n",
    "        #for index, row in dataframe[1].iterrows():\n",
    "        #    filtered_df = pd.DataFrame([row.to_dict()])\n",
    "        \n",
    "        for _, point in filtered_df.iloc[:, 1:].T.iterrows():\n",
    "            data[point.name].append([dataframe[0], point.iloc[0]])\n",
    "        \n",
    "        max_len = max(len(lst) for lst in data.values())\n",
    "        for key in data:\n",
    "            while len(data[key]) < max_len:\n",
    "                data[key].append(None)\n",
    "                \n",
    "        #break\n",
    "    indexes = pd.DataFrame(dict(data))\n",
    "    #display(indexes)\n",
    "    \n",
    "    for _, i in indexes.T.iterrows():\n",
    "        # Konwersja danych do słownika\n",
    "        pollution_data = {item[0]: float(item[1]) if item[1] != 'nan' else None for item in i.dropna()}\n",
    "            \n",
    "        # Tworzenie serii Pandas ze słownika\n",
    "        pollution_series = pd.Series(pollution_data)\n",
    "        \n",
    "        # Wywołanie funkcji calculate_air_quality\n",
    "        #try:\n",
    "        air_quality = calculate_air_quality(pollution_series)\n",
    "                \n",
    "        station_data = gdf3[gdf3['StationID'] == i.name]\n",
    "        #print(station_data)\n",
    "        if not station_data.empty:  \n",
    "            lat = station_data['lat'].iloc[0]\n",
    "            long = station_data['long'].iloc[0]\n",
    "            wojewodztwo = station_data['wojewodztwo'].iloc[0]\n",
    "            qualities.append([i.name, wojewodztwo, [long, lat], air_quality])\n",
    "        #except Exception as e:\n",
    "        #    print(f\"Błąd podczas obliczania jakości powietrza dla {i.name}: {e}\")\n",
    "   \n",
    "    #geojson_data = convert_to_geojson(qualities, current_date)\n",
    "    all_data.append([current_date, qualities])\n",
    "    \n",
    "    current_date += interval         \n",
    "#display(qualities)\n",
    "display(all_data)\n",
    "print(len(all_data))\n",
    "    \n",
    "    "
   ],
   "id": "54f7023d3934a88b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "69241a9e1a64262d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
